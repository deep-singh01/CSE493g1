{"cells":[{"cell_type":"code","execution_count":2,"id":"976b833c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"976b833c","executionInfo":{"status":"ok","timestamp":1746596427159,"user_tz":420,"elapsed":81967,"user":{"displayName":"Deepesh Singh","userId":"16229153260203355698"}},"outputId":"f3985aed-3712-4877-b008-8064796856bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/cse493g1/assignments/assignment3_colab/assignment3/cse493g1/datasets\n","/content/drive/My Drive/cse493g1/assignments/assignment3_colab/assignment3\n"]}],"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cse493g1/assignments/assignment3/'\n","FOLDERNAME = 'cse493g1/assignments/assignment3_colab/assignment3/'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","# This downloads the COCO dataset to your Drive\n","# if it doesn't already exist.\n","%cd /content/drive/My\\ Drive/$FOLDERNAME/cse493g1/datasets/\n","!bash get_datasets.sh\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"]},{"cell_type":"markdown","id":"39ae03a5","metadata":{"id":"39ae03a5"},"source":["# Multi-Layer Fully Connected Network Part 2\n","In this exercise, you will extend your fully connected network from Assignment 2 with Dropout and Normalization Layers. First, you will copy and paste all the necessary parts from Assignment 2. Then you will re-train your model from A2 as a baseline. Next, you will complete the batchnorm and dropout notebook, and then return to this notebook and create an improved model using dropout and normalization."]},{"cell_type":"code","execution_count":3,"id":"d3ff9493","metadata":{"tags":["pdf-ignore"],"colab":{"base_uri":"https://localhost:8080/"},"id":"d3ff9493","executionInfo":{"status":"ok","timestamp":1746596478224,"user_tz":420,"elapsed":3932,"user":{"displayName":"Deepesh Singh","userId":"16229153260203355698"}},"outputId":"79d02605-f108-4cf2-da0a-a709bc3919df"},"outputs":[{"output_type":"stream","name":"stdout","text":["=========== You can safely ignore the message below if you are NOT working on ConvolutionalNetworks.ipynb ===========\n","\tYou will need to compile a Cython extension for a portion of this assignment.\n","\tThe instructions to do this will be given in a section of the notebook below.\n"]}],"source":["# Setup cell.\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from cse493g1.classifiers.fc_net import *\n","from cse493g1.data_utils import get_CIFAR10_data\n","from cse493g1.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n","from cse493g1.solver import Solver\n","\n","%matplotlib inline\n","plt.rcParams[\"figure.figsize\"] = (10.0, 8.0)  # Set default size of plots.\n","plt.rcParams[\"image.interpolation\"] = \"nearest\"\n","plt.rcParams[\"image.cmap\"] = \"gray\"\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","def rel_error(x, y):\n","    \"\"\"Returns relative error.\"\"\"\n","    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"]},{"cell_type":"code","execution_count":4,"id":"67de3ab4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67de3ab4","executionInfo":{"status":"ok","timestamp":1746596490392,"user_tz":420,"elapsed":12162,"user":{"displayName":"Deepesh Singh","userId":"16229153260203355698"}},"outputId":"a7927990-3353-47d1-f0cf-e7cacb71d120"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train: (49000, 3, 32, 32)\n","y_train: (49000,)\n","X_val: (1000, 3, 32, 32)\n","y_val: (1000,)\n","X_test: (1000, 3, 32, 32)\n","y_test: (1000,)\n"]}],"source":["# Load the (preprocessed) CIFAR-10 data.\n","data = get_CIFAR10_data()\n","for k, v in list(data.items()):\n","    print(f\"{k}: {v.shape}\")"]},{"cell_type":"markdown","id":"8ded933c","metadata":{"id":"8ded933c"},"source":["# Copy necessary parts from A2.\n","Fill in the following functions by copying and pasting your answers from A2:\n","`affine_forward` in `cse493g1/layers.py`\n","`affine_backward` in `cse493g1/layers.py`\n","`relu_forward` in `cse493g1/layers.py`\n","`relu_backward` in `cse493g1/layers.py`\n","`softmax_loss` in `cse493g1/layers.py`\n","`sgd_momentum` in `cse493g1/optim.py`\n","`rmsprop` in `cse493g1/optim.py`\n","`adam` in `cse493g1/optim.py`\n","\n"]},{"cell_type":"markdown","id":"53fc4ab5","metadata":{"id":"53fc4ab5"},"source":["# Train baseline model from A2\n","Copy and Paste your `FullyConnectedNet` model from `cse493g1/classifiers/fc_net.py` in Assignment 2 into `FullyConnectedNetBasic` in the file `cse493g1/classifiers/fc_net.py` in this assignment. Use the best hyperparms that you found from the previous assignment to train this model. Call this model `best_model_basic`"]},{"cell_type":"code","execution_count":5,"id":"05297a59","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05297a59","executionInfo":{"status":"ok","timestamp":1746596771827,"user_tz":420,"elapsed":281434,"user":{"displayName":"Deepesh Singh","userId":"16229153260203355698"}},"outputId":"7c1deb4e-00cc-47ab-b868-b0893dfa0c1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["lr: 0.0003925808783477074 reg: 0.0036575163373692636 weight_scale: 0.011202710215900405 val_acc: 0.296\n","lr: 0.0002274010834106172 reg: 0.0006755276708708243 weight_scale: 0.022557776416818935 val_acc: 0.346\n","lr: 1.0636265157462757e-05 reg: 0.00022154148812624817 weight_scale: 0.01592147230529891 val_acc: 0.147\n","lr: 0.0003917214003249585 reg: 0.000498429362684529 weight_scale: 0.04737336239741938 val_acc: 0.329\n","lr: 0.0001352076302376644 reg: 0.001330136726115873 weight_scale: 0.02140827596175686 val_acc: 0.316\n","lr: 7.532516217500079e-05 reg: 0.0004503689828323332 weight_scale: 0.08073300178474309 val_acc: 0.178\n","lr: 3.9993974349762285e-05 reg: 0.000547429121905529 weight_scale: 0.08804693282140691 val_acc: 0.117\n","lr: 2.0864629014289815e-05 reg: 0.0017500158909523405 weight_scale: 0.03924156965462203 val_acc: 0.196\n","lr: 6.843185285291299e-05 reg: 0.0001568150334451038 weight_scale: 0.011006430751742033 val_acc: 0.221\n","lr: 0.00012826119728256014 reg: 0.0004015391885253266 weight_scale: 0.04288120501082788 val_acc: 0.28\n","lr: 3.7830132921368684e-05 reg: 0.006492450212837622 weight_scale: 0.035164334556443425 val_acc: 0.239\n","lr: 0.00017733510689307638 reg: 0.0002470503203955001 weight_scale: 0.03919992870042474 val_acc: 0.315\n","lr: 1.158731465431655e-05 reg: 0.002582345654015077 weight_scale: 0.08000187070478505 val_acc: 0.081\n","lr: 8.849340636044035e-05 reg: 0.000599311111763245 weight_scale: 0.02241430806526939 val_acc: 0.311\n","lr: 4.85462546579662e-05 reg: 0.0027444593048918113 weight_scale: 0.018107861226781145 val_acc: 0.208\n","lr: 7.275386293053624e-05 reg: 0.007788812150014651 weight_scale: 0.012979764811052535 val_acc: 0.228\n","lr: 1.816004742614483e-05 reg: 0.0017581261939117242 weight_scale: 0.08302056425482472 val_acc: 0.103\n","lr: 0.0005949050684729119 reg: 0.0003373804182494457 weight_scale: 0.013248361365843503 val_acc: 0.308\n","lr: 1.058935544160869e-05 reg: 0.0001160473881158284 weight_scale: 0.026447805758950046 val_acc: 0.179\n","lr: 0.0002245140015002245 reg: 0.007202927273407977 weight_scale: 0.012856381208120316 val_acc: 0.272\n","lr: 5.546389296124737e-05 reg: 0.0012401842513117376 weight_scale: 0.0324487194513549 val_acc: 0.262\n","lr: 0.0001521831558803049 reg: 0.00015409380788954387 weight_scale: 0.027816973115339764 val_acc: 0.328\n","lr: 0.00027690323994762124 reg: 0.002279746875427159 weight_scale: 0.0798377496965134 val_acc: 0.197\n","lr: 0.00018414883695699722 reg: 0.005324028278335483 weight_scale: 0.011266714097141629 val_acc: 0.275\n","lr: 4.04092963442496e-05 reg: 0.0006040985600099712 weight_scale: 0.05996776575489235 val_acc: 0.156\n","lr: 6.960216035442877e-05 reg: 0.0028946842500415437 weight_scale: 0.013065068057557033 val_acc: 0.223\n","lr: 0.00037007547804510023 reg: 0.0001020127526355686 weight_scale: 0.07255990023849085 val_acc: 0.216\n","lr: 0.0006408317553720895 reg: 0.0005187895769907945 weight_scale: 0.03064252470864396 val_acc: 0.354\n","lr: 0.0001912849531419047 reg: 0.00012018320370053484 weight_scale: 0.010463183150579737 val_acc: 0.295\n","lr: 3.407510358202464e-05 reg: 0.008296815173703889 weight_scale: 0.010641155736800533 val_acc: 0.171\n","\n","best_val: 0.354\n","best_params: {'lr': 0.0006408317553720895, 'reg': 0.0005187895769907945, 'weight_scale': 0.03064252470864396}\n","Best val accuracy: 0.538\n"]}],"source":["best_model_basic = None\n","\n","################################################################################\n","# TODO: Train the best FullyConnectedNetBasic that you can on CIFAR-10. Store your best model in  #\n","# the best_model_basic variable.                                                     #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","params = {}\n","best_val = -1\n","iters = 30\n","\n","num_train = 700\n","small_data = {\n","  'X_train': data['X_train'][:num_train],\n","  'y_train': data['y_train'][:num_train],\n","  'X_val': data['X_val'],\n","  'y_val': data['y_val']\n","}\n","\n","for i in range(iters):\n","  lr = 10**np.random.uniform(-5, -3)\n","  reg = 10**np.random.uniform(-4, -2)\n","  weight_scale = 10**np.random.uniform(-2, -1)\n","\n","  model = FullyConnectedNetBasic(\n","    [100, 100, 100, 100],\n","    weight_scale=weight_scale,\n","    reg=reg,\n","    dtype=np.float64\n","  )\n","\n","  solver = Solver(\n","    model,\n","    small_data,\n","    num_epochs=15,\n","    batch_size=128,\n","    update_rule='adam',\n","    optim_config={'learning_rate': lr},\n","    verbose=False\n","  )\n","  solver.train()\n","\n","  model_val = solver.best_val_acc\n","  if model_val > best_val:\n","    best_val = model_val\n","    best_params = {\n","      'lr': lr,\n","      'reg': reg,\n","      'weight_scale': weight_scale\n","    }\n","  print(f'lr: {lr}', f'reg: {reg}', f'weight_scale: {weight_scale}', f'val_acc: {model_val}')\n","\n","print(f'\\nbest_val: {best_val}')\n","print(f'best_params: {best_params}')\n","\n","best_model_basic = FullyConnectedNetBasic(\n","  [100, 100, 100, 100],\n","  weight_scale=best_params['weight_scale'],\n","  reg=best_params['reg'],\n","  dtype=np.float64\n",")\n","best_solver = Solver(\n","  best_model_basic,\n","  data,\n","  num_epochs=15,\n","  batch_size=128,\n","  update_rule='adam',\n","  optim_config={'learning_rate': best_params['lr']},\n","  verbose=False\n",")\n","best_solver.train()\n","\n","print(f'Best val accuracy: {best_solver.best_val_acc}')\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                              END OF YOUR CODE                                #\n","################################################################################"]},{"cell_type":"markdown","id":"a8db530b","metadata":{"id":"a8db530b"},"source":["# Evaluate baseline model from A2\n","Evaluate above baseline model."]},{"cell_type":"code","execution_count":6,"id":"94044fb3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94044fb3","executionInfo":{"status":"ok","timestamp":1746596771892,"user_tz":420,"elapsed":62,"user":{"displayName":"Deepesh Singh","userId":"16229153260203355698"}},"outputId":"b14b1502-e04a-44f4-c072-9b4fe9bd731f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation set accuracy:  0.538\n","Test set accuracy:  0.49\n"]}],"source":["y_test_pred = np.argmax(best_model_basic.loss(data['X_test']), axis=1)\n","y_val_pred = np.argmax(best_model_basic.loss(data['X_val']), axis=1)\n","print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n","print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"]},{"cell_type":"markdown","id":"23898874","metadata":{"id":"23898874"},"source":["# Train improved model\n","Design a new model in `FullyConnectedNetImproved` in the file `cse493g1/classifiers/fc_net.py`. You can start by having `FullyConnectedNetImproved` be the same design as `FullyConnectedNetBasic`. Next, complete the BatchNormoralization.ipynb and Dropout.ipynb notebooks. Then return to this notebook and complete `FullyConnectedNetImproved` by adding in batchnorm and dropout. Try to beat the accuracy of your baseline model! You may have to adjust your hyperparameters."]},{"cell_type":"code","execution_count":22,"id":"34f76c73","metadata":{"scrolled":false,"id":"34f76c73","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746599735879,"user_tz":420,"elapsed":350907,"user":{"displayName":"Deepesh Singh","userId":"16229153260203355698"}},"outputId":"9a3889b8-8dbc-4a98-f211-47661e23e472"},"outputs":[{"output_type":"stream","name":"stdout","text":["lr: 0.0021599778570350146 reg: 0.00023634950689347428 weight_scale: 0.030992813132862913 dropout: 0.8425779681580954 val_acc: 0.351\n","lr: 0.0036876238861453304 reg: 0.0002881124918408124 weight_scale: 0.017682647558089085 dropout: 0.8080849321281375 val_acc: 0.316\n","lr: 0.0042425833397861865 reg: 0.00041921676072849445 weight_scale: 0.03134389928124231 dropout: 0.8470505474732906 val_acc: 0.322\n","lr: 0.004458982491854083 reg: 0.00013565026064037608 weight_scale: 0.02189257212432032 dropout: 0.873774269986016 val_acc: 0.327\n","lr: 0.004994151708533769 reg: 0.0003158040562270049 weight_scale: 0.017930826460040978 dropout: 0.8330613737106323 val_acc: 0.337\n","lr: 0.002056333966264573 reg: 0.00033344763437836067 weight_scale: 0.02750622105613915 dropout: 0.781313795616098 val_acc: 0.343\n","lr: 0.003714535715181818 reg: 0.0003905114189672309 weight_scale: 0.014708678579181612 dropout: 0.7337628378504379 val_acc: 0.334\n","lr: 0.0038988118185525494 reg: 0.00037347624320418625 weight_scale: 0.013228284347481233 dropout: 0.7376393729163854 val_acc: 0.313\n","lr: 0.0022770545066690025 reg: 0.0002147130692427662 weight_scale: 0.027936916067274165 dropout: 0.7472494413934885 val_acc: 0.346\n","lr: 0.002027216034582872 reg: 0.00019796020374480736 weight_scale: 0.01219294594868533 dropout: 0.704960012200646 val_acc: 0.323\n","lr: 0.003546975506744749 reg: 0.00017330551677727162 weight_scale: 0.013931430372367179 dropout: 0.8804965054269563 val_acc: 0.338\n","lr: 0.003888890434597957 reg: 0.000176605817733737 weight_scale: 0.024656648845629205 dropout: 0.7381687824743605 val_acc: 0.312\n","lr: 0.0031623255720755867 reg: 0.00014711842971675186 weight_scale: 0.02925376861078858 dropout: 0.7030906163883542 val_acc: 0.326\n","lr: 0.003609813971099441 reg: 0.0001435825634018974 weight_scale: 0.010100232183515254 dropout: 0.8351782519924138 val_acc: 0.339\n","lr: 0.0032567265566759967 reg: 0.00017052530468856036 weight_scale: 0.010629729134256014 dropout: 0.7016254492651305 val_acc: 0.329\n","lr: 0.0025073272516623096 reg: 0.00018465140903619606 weight_scale: 0.017323722116517407 dropout: 0.8450082392425512 val_acc: 0.342\n","lr: 0.004510107198077338 reg: 0.00023666039291437397 weight_scale: 0.017411450216142793 dropout: 0.7820917406043657 val_acc: 0.316\n","lr: 0.0038734638049819944 reg: 0.00013238551010568596 weight_scale: 0.015414433697575313 dropout: 0.720040756432564 val_acc: 0.324\n","lr: 0.0021336516717606075 reg: 0.0001336957189228878 weight_scale: 0.01604856423396951 dropout: 0.8945419587865624 val_acc: 0.334\n","lr: 0.002068208317156039 reg: 0.00035813645853185306 weight_scale: 0.02616594214491944 dropout: 0.733431594173863 val_acc: 0.33\n","lr: 0.0027232325943914166 reg: 0.0002245767920340934 weight_scale: 0.013854192172101536 dropout: 0.8947887881374095 val_acc: 0.364\n","lr: 0.003426196737173907 reg: 0.00032361907688199744 weight_scale: 0.024103381633442954 dropout: 0.8493280872011784 val_acc: 0.335\n","lr: 0.003409585828099644 reg: 0.00022105612669984665 weight_scale: 0.028720349118335254 dropout: 0.8013610637446937 val_acc: 0.341\n","lr: 0.0028973291170310265 reg: 0.0001292149188469808 weight_scale: 0.012452810518636932 dropout: 0.7076394824111323 val_acc: 0.309\n","lr: 0.003990503505376613 reg: 0.0004953856263616002 weight_scale: 0.024307310196263657 dropout: 0.8610210095519711 val_acc: 0.363\n","lr: 0.0034388431868793454 reg: 0.00017114052485459494 weight_scale: 0.01440105471606455 dropout: 0.755334803310351 val_acc: 0.337\n","lr: 0.0030326691951655604 reg: 0.00039357960806666627 weight_scale: 0.013585354482720084 dropout: 0.7778170131455945 val_acc: 0.353\n","lr: 0.0030102853075512173 reg: 0.0004411657899127987 weight_scale: 0.023530196273486365 dropout: 0.7959767992821967 val_acc: 0.339\n","lr: 0.002441577667613199 reg: 0.00022358402130333183 weight_scale: 0.031005725408981426 dropout: 0.8673920137647186 val_acc: 0.339\n","lr: 0.0030183078545002514 reg: 0.00040429127462879733 weight_scale: 0.01619481934693275 dropout: 0.7867301202739461 val_acc: 0.34\n","\n","best_val: 0.364\n","best_params: {'lr': 0.0027232325943914166, 'reg': 0.0002245767920340934, 'weight_scale': 0.013854192172101536, 'dropout': 0.8947887881374095}\n","Best val accuracy: 0.536\n"]}],"source":["best_model_improved = None\n","\n","################################################################################\n","# TODO: Train the best FullyConnectedNetImproved that you can on CIFAR-10. You might   #\n","# find batch/layer normalization and dropout useful. Store your best model in  #\n","# the best_mode_improved variable.                                                     #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","params = {}\n","best_val = -1\n","iters = 30\n","\n","num_train = 700\n","small_data = {\n","  'X_train': data['X_train'][:num_train],\n","  'y_train': data['y_train'][:num_train],\n","  'X_val': data['X_val'],\n","  'y_val': data['y_val']\n","}\n","\n","for i in range(iters):\n","  lr = 10**np.random.uniform(-2.7, -2.3)\n","  reg = 10**np.random.uniform(-3.9, -3.3)\n","  weight_scale = 10**np.random.uniform(-2, -1.5)\n","  dropout = np.random.uniform(.7, .9)\n","\n","  model = FullyConnectedNetImproved(\n","    [100, 100, 100, 100],\n","    weight_scale=weight_scale,\n","    reg=reg,\n","    dropout_keep_ratio=dropout,\n","    normalization='batchnorm',\n","    dtype=np.float64\n","  )\n","\n","  solver = Solver(\n","    model,\n","    small_data,\n","    num_epochs=15,\n","    batch_size=128,\n","    update_rule='adam',\n","    optim_config={'learning_rate': lr},\n","    verbose=False\n","  )\n","  solver.train()\n","\n","  model_val = solver.best_val_acc\n","  if model_val > best_val:\n","    best_val = model_val\n","    best_params = {\n","      'lr': lr,\n","      'reg': reg,\n","      'weight_scale': weight_scale,\n","      'dropout': dropout\n","    }\n","  print(f'lr: {lr}', f'reg: {reg}', f'weight_scale: {weight_scale}', f'dropout: {dropout}', f'val_acc: {model_val}')\n","\n","print(f'\\nbest_val: {best_val}')\n","print(f'best_params: {best_params}')\n","\n","best_model_improved = FullyConnectedNetImproved(\n","  [100, 100, 100, 100],\n","  weight_scale=best_params['weight_scale'],\n","  reg=best_params['reg'],\n","  dropout_keep_ratio=best_params['dropout'],\n","  normalization='batchnorm',\n","  dtype=np.float64\n",")\n","best_solver = Solver(\n","  best_model_improved,\n","  data,\n","  num_epochs=15,\n","  batch_size=128,\n","  update_rule='adam',\n","  optim_config={'learning_rate': best_params['lr']},\n","  verbose=False\n",")\n","best_solver.train()\n","\n","print(f'Best val accuracy: {best_solver.best_val_acc}')\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                              END OF YOUR CODE                                #\n","################################################################################"]},{"cell_type":"markdown","id":"881838d6","metadata":{"id":"881838d6"},"source":["# Test Your Model!\n","Run your best model on the validation and test sets. Are you able to outperform the baseline model that has no Batchnorm or Dropout?"]},{"cell_type":"code","execution_count":23,"id":"b734eb14","metadata":{"id":"b734eb14","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746599736178,"user_tz":420,"elapsed":302,"user":{"displayName":"Deepesh Singh","userId":"16229153260203355698"}},"outputId":"c9528e29-40da-4786-a554-c97343bdd33e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation set accuracy:  0.529\n","Test set accuracy:  0.511\n"]}],"source":["y_test_pred = np.argmax(best_model_improved.loss(data['X_test']), axis=1)\n","y_val_pred = np.argmax(best_model_improved.loss(data['X_val']), axis=1)\n","print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n","print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}